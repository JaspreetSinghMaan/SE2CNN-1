{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic usage of the se2cnn library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This jupyter demo will contain the basic usage examples of the se2cnn library with applications to digit recognition in the MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Impor tensorflow and numpy\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math as m\n",
    "import time\n",
    "\n",
    "# For plotting\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Add the library to the system path\n",
    "import os,sys\n",
    "se2cnn_source =  os.path.join(os.getcwd(),'..')\n",
    "if se2cnn_source not in sys.path:\n",
    "    sys.path.append(se2cnn_source)\n",
    "\n",
    "# Import the library\n",
    "import se2cnn.layers\n",
    "import se2cnn.rotation_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIS dataset consists of 28x28 images of handwritten characters. We are going to classify each input image into 1 of the 10 classes (the digits 0 to 9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "train_data = mnist.train.images # Returns np.array\n",
    "train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "eval_data = mnist.test.images # Returns np.array\n",
    "eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default the data is formatted as flattened arrays. Here were format them as 2D feature maps (with only 1 channel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xf8935c7828>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reshape to 2D multi-channel images\n",
    "train_data_2D = train_data.reshape([len(train_data),28,28,1]) # [batch_size, Nx, Ny, Nc]\n",
    "eval_data_2D = eval_data.reshape([len(eval_data),28,28,1])\n",
    "\n",
    "# Plot the first sample\n",
    "plt.plot()\n",
    "plt.title('Digit = %d' % train_labels[0])\n",
    "plt.imshow(train_data_2D[0,:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "graph.as_default()\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernel size and number of orientations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ntheta = 8\n",
    "Nx=Ny=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_ph = tf.placeholder( dtype = tf.float32, shape = [None,28,28,1] )\n",
    "labels_ph = tf.placeholder( dtype = tf.int32, shape = [None,] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare for the first layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_in = inputs_ph\n",
    "Nc_in = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(28), Dimension(28), Dimension(1)])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_in.get_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 1: The lifting layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z2-SE2N KERNELS SHAPE: (8, 5, 5, 1, 6)\n",
      "OUTPUT SE2N ACTIVATIONS SHAPE: (?, 8, 24, 24, 6)\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(\"Layer_{}\".format(1)) as _scope:\n",
    "    ## Settings\n",
    "    Nc_out = 6\n",
    "\n",
    "    ## Perform convolution-max pooling-relu\n",
    "    # Lifting layer\n",
    "    tensor_out, kernels_raw, kernels_formatted = se2cnn.layers.z2_se2n(\n",
    "                            input_tensor = tensor_in,\n",
    "                            kernel_shape = [Nx, Ny, Nc_in, Nc_out],\n",
    "                            orientations_nb = Ntheta)\n",
    "    # Max-pooling\n",
    "    tensor_out = se2cnn.layers.spatial_max_pool( tensor=tensor_out, nbOrientations=Ntheta)\n",
    "    # ReLU\n",
    "    tensor_out = tf.nn.relu(tensor_out)\n",
    "\n",
    "    ## Prepare for the next layer\n",
    "    tensor_in = tensor_out\n",
    "    Nc_in = Nc_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(8), Dimension(12), Dimension(12), Dimension(6)])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_in.get_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 2: SE2-conv, max-pool, relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SE2N-SE2N BASE KERNEL SHAPE: (8, 5, 5, 6, 16)\n",
      "OUTPUT SE2N ACTIVATIONS SHAPE: (?, 8, 8, 8, 16)\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(\"Layer_{}\".format(2)) as _scope:\n",
    "    ## Settings\n",
    "    Nc_out = 16\n",
    "\n",
    "    ## Perform convolution-max pooling-relu\n",
    "    # Lifting layer\n",
    "    tensor_out, kernels_raw, kernels_formatted = se2cnn.layers.se2n_se2n(\n",
    "                            input_tensor = tensor_in,\n",
    "                            kernel_shape = [5, 5, Nc_in, Nc_out],\n",
    "                            orientations_nb = Ntheta)\n",
    "    # Max-pooling\n",
    "    tensor_out = se2cnn.layers.spatial_max_pool( tensor=tensor_out, nbOrientations=Ntheta)\n",
    "    # ReLU\n",
    "    tensor_out = tf.nn.relu(tensor_out)\n",
    "\n",
    "    ## Prepare for the next layer\n",
    "    tensor_in = tensor_out\n",
    "    Nc_in = Nc_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(8), Dimension(4), Dimension(4), Dimension(16)])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_in.get_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 3: Projection to 2D plane followed by fully connected layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximum intensity projection over theta, and flatten to 1D vector per sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_in = tf.reduce_max( tensor_in, axis=1) #--> [BatchSize, Height, Width, ChannelsOut]        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Followed by fully connected convolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z2-Z2 KERNEL SHAPE: (4, 4, 16, 120)\n",
      "OUTPUT Z2 ACTIVATIONS SHAPE: (?, 1, 1, 120)\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(\"Layer_{}\".format(3)) as _scope:\n",
    "    ## Settings\n",
    "    Nc_out = 120\n",
    "\n",
    "    ## Perform convolution-max pooling-relu\n",
    "    # 2D convolution layer (fully connected)\n",
    "    tensor_out, kernels_raw = se2cnn.layers.z2_z2( tensor_in , [4,4,Nc_in,Nc_out])\n",
    "    \n",
    "    # ReLU\n",
    "    tensor_out = tf.nn.relu(tensor_out)\n",
    "\n",
    "    ## Prepare for the next layer\n",
    "    tensor_in = tensor_out\n",
    "    Nc_in = Nc_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(1), Dimension(1), Dimension(120)])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_in.get_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 4: fully connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z2-Z2 KERNEL SHAPE: (1, 1, 120, 84)\n",
      "OUTPUT Z2 ACTIVATIONS SHAPE: (?, 1, 1, 84)\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(\"Layer_{}\".format(4)) as _scope:\n",
    "    ## Settings\n",
    "    Nc_out = 84\n",
    "\n",
    "    ## Perform convolution-max pooling-relu\n",
    "    # 2D convolution layer (fully connected)\n",
    "    tensor_out, kernels_raw = se2cnn.layers.z2_z2( tensor_in , [1,1,Nc_in,Nc_out])\n",
    "    \n",
    "    # ReLU\n",
    "    tensor_out = tf.nn.relu(tensor_out)\n",
    "\n",
    "    ## Prepare for the next layer\n",
    "    tensor_in = tensor_out\n",
    "    Nc_in = Nc_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(1), Dimension(1), Dimension(84)])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_in.get_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 5: fully connected to output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z2-Z2 KERNEL SHAPE: (1, 1, 84, 10)\n",
      "OUTPUT Z2 ACTIVATIONS SHAPE: (?, 1, 1, 10)\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(\"Layer_{}\".format(5)) as _scope:\n",
    "    ## Settings\n",
    "    Nc_out = 10\n",
    "\n",
    "    ## Perform convolution-max pooling-relu\n",
    "    # 2D convolution layer (fully connected)\n",
    "    tensor_out, kernels_raw = se2cnn.layers.z2_z2( tensor_in , [1,1,Nc_in,Nc_out])\n",
    "    \n",
    "    # The output logits\n",
    "    logits = tensor_out[:,0,0,:]\n",
    "    predictions = tf.argmax(input=logits, axis=1)\n",
    "    probabilities = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(10)])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.get_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the loss and the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-entropy loss\n",
    "loss = tf.losses.sparse_softmax_cross_entropy(labels=labels_ph, logits=logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the Training Op (for TRAIN mode)\n",
    "#optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train_op = optimizer.minimize(\n",
    "    loss=loss,\n",
    "    global_step=tf.train.get_global_step())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Start the (GPU) session\n",
    "initializer = tf.global_variables_initializer()\n",
    "session = tf.Session(graph=tf.get_default_graph()) #-- Session created\n",
    "session.run(initializer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each epoch we pass over all input samples in batch sizes of batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "n_epochs=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop over the input stack in batch of size \"batch_size\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0  finished... Average loss =  0.2657618205299674 , time =  38.73426127433777\n",
      "Epoch  1  finished... Average loss =  0.06122371554157602 , time =  36.9645733833313\n",
      "Epoch  2  finished... Average loss =  0.04195345913728651 , time =  36.78606295585632\n",
      "Epoch  3  finished... Average loss =  0.033053749711209314 , time =  36.81812500953674\n",
      "Epoch  4  finished... Average loss =  0.025597977867710342 , time =  36.971532583236694\n",
      "Epoch  5  finished... Average loss =  0.022329220299702354 , time =  37.07286238670349\n",
      "Epoch  6  finished... Average loss =  0.018559924176229828 , time =  37.02373194694519\n",
      "Epoch  7  finished... Average loss =  0.016587892656473972 , time =  37.11591577529907\n",
      "Epoch  8  finished... Average loss =  0.01463253839607112 , time =  37.55608773231506\n",
      "Epoch  9  finished... Average loss =  0.01007095366540133 , time =  37.54104709625244\n"
     ]
    }
   ],
   "source": [
    "for epoch_nr in range(n_epochs):\n",
    "    loss_average = 0\n",
    "    data = train_data_2D\n",
    "    labels = train_labels\n",
    "    # KBatch settings\n",
    "    NItPerEpoch = m.floor(len(data)/batch_size) #number of iterations per epoch\n",
    "    samples=np.random.permutation(len(data))\n",
    "    # Loop over dataset\n",
    "    tStart = time.time()\n",
    "    for iteration in range(NItPerEpoch):\n",
    "        feed_dict = {\n",
    "                inputs_ph: np.array(data[samples[iteration*batch_size:(iteration+1)*batch_size]]),\n",
    "                labels_ph: np.array(labels[samples[iteration*batch_size:(iteration+1)*batch_size]])\n",
    "                }\n",
    "        operators_output = session.run([ loss , train_op ], feed_dict)\n",
    "        loss_average += operators_output[0]/NItPerEpoch\n",
    "    tElapsed = time.time() - tStart\n",
    "    print('Epoch ' , epoch_nr , ' finished... Average loss = ' , loss_average , ', time = ',tElapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "labels_pred = []\n",
    "for i in range(round(len(eval_data_2D)/batch_size)):\n",
    "    [ labels_pred_batch ] = session.run([ predictions ], { inputs_ph: eval_data_2D[i*batch_size:(i+1)*batch_size] })\n",
    "    labels_pred = labels_pred + list(labels_pred_batch)\n",
    "labels_pred = np.array(labels_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the first 10 results with the ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0 4 1 4 9 5 9]\n",
      "[7 2 1 0 4 1 4 9 5 9]\n"
     ]
    }
   ],
   "source": [
    "print(labels_pred[0:10])\n",
    "print(eval_labels[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy (average nr of successes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9907"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((labels_pred - eval_labels)**2==0).astype(float).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total nr of errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((labels_pred - eval_labels)**2>0).astype(float).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
